{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################APPLE########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "107/107 [==============================] - 43s 375ms/step - loss: 0.3078 - accuracy: 0.8719\n",
      "Epoch 2/5\n",
      "107/107 [==============================] - 38s 354ms/step - loss: 0.1014 - accuracy: 0.9641\n",
      "Epoch 3/5\n",
      "107/107 [==============================] - 43s 405ms/step - loss: 0.0756 - accuracy: 0.9727\n",
      "Epoch 4/5\n",
      "107/107 [==============================] - 46s 430ms/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 5/5\n",
      "107/107 [==============================] - 40s 376ms/step - loss: 0.0189 - accuracy: 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Apple\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Apple\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Apple\\Apple\\train\\Apple Black rot\"\n",
    "class2_folder = r\"Apple\\Apple\\train\\Apple Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append(img_array)\n",
    "    return np.array(image_data)\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder)\n",
    "class1_labels = np.zeros(len(class1_data))  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder)\n",
    "class2_labels = np.ones(len(class2_data))  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data))\n",
    "train_labels = np.concatenate((class1_labels, class2_labels))\n",
    "\n",
    "# Create a simple CNN model\n",
    "model1 = keras.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(12, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model1.fit(train_data, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "model1.save(\"Apple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Apple\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Apple With Black Rot\" if prediction[0][0] < 0.5 else \"Healthy Apple\"\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "Prediction: Apple With Black Rot\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Apple\\Apple\\valid\\Apple Black rot\\AppleBlackRot(2).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "Prediction: Healthy Apple\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Apple\\Apple\\valid\\Apple Healthy\\AppleHealthy(10).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################POTATO###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "187/187 [==============================] - 73s 380ms/step - loss: 0.4714 - accuracy: 0.7872\n",
      "Epoch 2/5\n",
      "187/187 [==============================] - 82s 440ms/step - loss: 0.2990 - accuracy: 0.9489\n",
      "Epoch 3/5\n",
      "187/187 [==============================] - 66s 355ms/step - loss: 0.2555 - accuracy: 0.9633\n",
      "Epoch 4/5\n",
      "187/187 [==============================] - 65s 348ms/step - loss: 0.2243 - accuracy: 0.9686\n",
      "Epoch 5/5\n",
      "187/187 [==============================] - 65s 349ms/step - loss: 0.1891 - accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Potato\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Potato\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Potato\\Potato\\train\\Potato Early blight\"\n",
    "class2_folder = r\"Potato\\Potato\\train\\Potato Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append(img_array)\n",
    "    return np.array(image_data)\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder)\n",
    "class1_labels = np.zeros(len(class1_data))  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder)\n",
    "class2_labels = np.ones(len(class2_data))  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data))\n",
    "train_labels = np.concatenate((class1_labels, class2_labels))\n",
    "\n",
    "# Create a simple CNN model\n",
    "model2 = keras.Sequential([\n",
    "    layers.Conv2D(14, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(10, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(train_data, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "model2.save(\"Potato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Potato\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Potato With Early Blight\" if prediction[0][0] < 0.5 else \"Healthy Potato\"\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F582553520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F582553520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 236ms/step\n",
      "Prediction: Potato With Early Blight\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Potato\\Potato\\valid\\Potato Early blight\\PotatoEarlyBlight(2).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F5825A1E10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F5825A1E10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "Prediction: Healthy Potato\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r\"Potato\\Potato\\valid\\Potato Healthy\\PotatoHealthy(2).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################TOMATO#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "153/153 [==============================] - 144s 912ms/step - loss: 0.6771 - accuracy: 0.7237\n",
      "Epoch 2/5\n",
      "153/153 [==============================] - 147s 959ms/step - loss: 0.1837 - accuracy: 0.9475\n",
      "Epoch 3/5\n",
      "153/153 [==============================] - 137s 892ms/step - loss: 0.0552 - accuracy: 0.9837\n",
      "Epoch 4/5\n",
      "153/153 [==============================] - 135s 884ms/step - loss: 0.0265 - accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "153/153 [==============================] - 135s 884ms/step - loss: 0.0142 - accuracy: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Tomato\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Tomato\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Tomato\\Tomato\\train\\Tomato Bacterial spot\"\n",
    "class2_folder = r\"Tomato\\Tomato\\train\\Tomato Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append(img_array)\n",
    "    return np.array(image_data)\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder)\n",
    "class1_labels = np.zeros(len(class1_data))  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder)\n",
    "class2_labels = np.ones(len(class2_data))  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data))\n",
    "train_labels = np.concatenate((class1_labels, class2_labels))\n",
    "\n",
    "# Create a simple CNN model\n",
    "model3 = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model3.fit(train_data, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "model3.save(\"Tomato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Tomato\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Tomato backtorial Spot\" if prediction[0][0] < 0.5 else \"Healthy Tomato\"\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step\n",
      "Prediction: Tomato backtorial Spot\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Tomato\\Tomato\\valid\\Tomato Bacterial spot\\TomatoBacterialSpot(3).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "Prediction: Healthy Tomato\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r\"Tomato\\Tomato\\valid\\Tomato Healthy\\TomatoHealthy(3).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################CORN###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VAIBHAV\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 73s 950ms/step - loss: 0.0626 - accuracy: 0.9936\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 67s 902ms/step - loss: 0.0365 - accuracy: 0.9991\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 63s 848ms/step - loss: 0.0359 - accuracy: 0.9991\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 62s 840ms/step - loss: 0.0308 - accuracy: 0.9991\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 62s 839ms/step - loss: 0.1377 - accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Cron\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Cron\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Cron\\Corn\\train\\Corn Common rust\"\n",
    "class2_folder = r\"Cron\\Corn\\valid\\Corn Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path, class_label):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if the image is grayscale\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append((img_array, class_label))\n",
    "    return image_data\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder, 0)  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder, 1)  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data), axis=0)\n",
    "np.random.shuffle(train_data)  # Shuffle the data\n",
    "x_train = np.array([data[0] for data in train_data])\n",
    "y_train = np.array([data[1] for data in train_data])\n",
    "\n",
    "# Create a simple CNN model\n",
    "model4 = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Use softmax activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model4.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model4.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "model4.save(\"Cron\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Cron\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Corn With Common Rust\" if prediction[0][0] < 0.5 else \"Healthy Corn\"\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "Prediction: Healthy Corn\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Cron\\Corn\\valid\\Corn Healthy\\CornHealthy(1).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n",
      "Prediction: Healthy Corn\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r\"Cron\\Corn\\valid\\Corn Common rust\\CornCommonRust(10).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Bell Pepper##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VAIBHAV\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 159s 1s/step - loss: 0.3986 - accuracy: 0.8788\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 152s 980ms/step - loss: 0.1283 - accuracy: 0.9547\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 145s 939ms/step - loss: 0.0556 - accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 141s 907ms/step - loss: 0.0301 - accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 131s 847ms/step - loss: 0.0213 - accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bell Pepper\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bell Pepper\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Bell Pepper\\Bell pepper\\train\\Bell pepper Bacterial spot\"\n",
    "class2_folder = r\"Bell Pepper\\Bell pepper\\train\\Bell pepper Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path, class_label):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if the image is grayscale\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append((img_array, class_label))\n",
    "    return image_data\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder, 0)  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder, 1)  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data), axis=0)\n",
    "np.random.shuffle(train_data)  # Shuffle the data\n",
    "x_train = np.array([data[0] for data in train_data])\n",
    "y_train = np.array([data[1] for data in train_data])\n",
    "\n",
    "# Create a simple CNN model\n",
    "model5 = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Use softmax activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model5.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "\n",
    "model5.save(\"Bell Pepper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Bell Pepper\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Bell Pepper With Bactorial Spot\" if prediction[0][0] < 0.5 else \"Healthy Bell Pepper\"\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n",
      "Prediction: Bell Pepper With Bactorial Spot\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r\"Bell Pepper\\Bell pepper\\valid\\Bell pepper Bacterial spot\\BacterialSpot(3).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "Prediction: Bell Pepper With Bactorial Spot\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r\"Bell Pepper\\Bell pepper\\valid\\Bell pepper Healthy\\BellPepperHealthy(8).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################Strawberry####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "132/132 [==============================] - 49s 326ms/step - loss: 0.1852 - accuracy: 0.9279\n",
      "Epoch 2/5\n",
      "132/132 [==============================] - 42s 316ms/step - loss: 0.0627 - accuracy: 0.9801\n",
      "Epoch 3/5\n",
      "132/132 [==============================] - 43s 324ms/step - loss: 0.0380 - accuracy: 0.9903\n",
      "Epoch 4/5\n",
      "132/132 [==============================] - 42s 320ms/step - loss: 0.0227 - accuracy: 0.9948\n",
      "Epoch 5/5\n",
      "132/132 [==============================] - 42s 319ms/step - loss: 0.0152 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Strawberry\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Strawberry\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Strawberry\\Strawberry\\train\\Strawberry Leaf scorch\"\n",
    "class2_folder = r\"Strawberry\\Strawberry\\train\\Strawberry Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append(img_array)\n",
    "    return np.array(image_data)\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder)\n",
    "class1_labels = np.zeros(len(class1_data))  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder)\n",
    "class2_labels = np.ones(len(class2_data))  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data))\n",
    "train_labels = np.concatenate((class1_labels, class2_labels))\n",
    "\n",
    "# Create a simple CNN model\n",
    "model6 = keras.Sequential([\n",
    "    layers.Conv2D(12, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model6.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model6.fit(train_data, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "model6.save(\"Strawberry\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Strawberry\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Strawberry With Leaf Scorch\" if prediction[0][0] < 0.5 else \"Healthy Strawberry\"\n",
    "    return class_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n",
      "Prediction: Strawberry With Leaf Scorch\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Strawberry\\Strawberry\\valid\\Strawberry Leaf scorch\\StrawberryLeafScorch(2).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n",
      "Prediction: Healthy Strawberry\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Strawberry\\Strawberry\\valid\\Strawberry Healthy\\StrawberryHealthy(1).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Cherry############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "147/147 [==============================] - 66s 437ms/step - loss: 0.5223 - accuracy: 0.7738\n",
      "Epoch 2/5\n",
      "147/147 [==============================] - 57s 390ms/step - loss: 0.3343 - accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "147/147 [==============================] - 52s 355ms/step - loss: 0.2814 - accuracy: 0.9836\n",
      "Epoch 4/5\n",
      "147/147 [==============================] - 52s 355ms/step - loss: 0.2468 - accuracy: 0.9900\n",
      "Epoch 5/5\n",
      "147/147 [==============================] - 53s 357ms/step - loss: 0.2268 - accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Cherry\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Cherry\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Cherry\\Cherry\\train\\Cherry Powdery mildew\"\n",
    "class2_folder = r\"Cherry\\Cherry\\train\\Cherry Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append(img_array)\n",
    "    return np.array(image_data)\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder)\n",
    "class1_labels = np.zeros(len(class1_data))  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder)\n",
    "class2_labels = np.ones(len(class2_data))  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data))\n",
    "train_labels = np.concatenate((class1_labels, class2_labels))\n",
    "\n",
    "# Create a simple CNN model\n",
    "model7 = keras.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(12, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(12, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model7.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model7.fit(train_data, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "model7.save(\"Cherry\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Cherry\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Cherry With Powder Mildrew\" if prediction[0][0] < 0.5 else \"Healthy Cherry\"\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002505EC4EB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002505EC4EB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "Prediction: Healthy Cherry\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Cherry\\Cherry\\valid\\Cherry Healthy\\CherryHealthy(7).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "Prediction: Healthy Cherry\n"
     ]
    }
   ],
   "source": [
    "new_image_path = r\"Cherry\\Cherry\\valid\\Cherry Powdery mildew\\CherryPowderyMildew2.JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################PEACH##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "142/142 [==============================] - 69s 464ms/step - loss: 0.3854 - accuracy: 0.7965\n",
      "Epoch 2/5\n",
      "142/142 [==============================] - 55s 386ms/step - loss: 0.1357 - accuracy: 0.9568\n",
      "Epoch 3/5\n",
      "142/142 [==============================] - 50s 354ms/step - loss: 0.0882 - accuracy: 0.9737\n",
      "Epoch 4/5\n",
      "142/142 [==============================] - 50s 353ms/step - loss: 0.0624 - accuracy: 0.9841\n",
      "Epoch 5/5\n",
      "142/142 [==============================] - 51s 359ms/step - loss: 0.0410 - accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Peach\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Peach\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Peach\\Peach\\train\\Peach Bacterial spot\"\n",
    "class2_folder = r\"Peach\\Peach\\train\\Peach Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append(img_array)\n",
    "    return np.array(image_data)\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder)\n",
    "class1_labels = np.zeros(len(class1_data))  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder)\n",
    "class2_labels = np.ones(len(class2_data))  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data))\n",
    "train_labels = np.concatenate((class1_labels, class2_labels))\n",
    "\n",
    "# Create a simple CNN model\n",
    "model8 = keras.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(12, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(12, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model8.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model8.fit(train_data, train_labels, epochs=5, batch_size=32)\n",
    "model8.save(\"Peach\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Peach\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Peach With Bacterial Spot\" if prediction[0][0] < 0.5 else \"Healthy Peach\"\n",
    "    return class_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "Prediction: Peach With Bacterial Spot\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Peach\\Peach\\valid\\Peach Bacterial spot\\PeachBacterialSpot(2).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Prediction: Healthy Peach\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Peach\\Peach\\valid\\Peach Healthy\\PeachHealthy(3).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################Citrus########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VAIBHAV\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 20s 1s/step - loss: 2.3066 - accuracy: 0.6717\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 19s 1s/step - loss: 0.5609 - accuracy: 0.7820\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 18s 1s/step - loss: 0.4713 - accuracy: 0.7920\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 18s 1s/step - loss: 0.4141 - accuracy: 0.8195\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 18s 1s/step - loss: 0.3643 - accuracy: 0.8722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Citrus\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Citrus\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Citrus\\Citrus\\train\\Citrus Black spot\"\n",
    "class2_folder = r\"Citrus\\Citrus\\train\\Citrus Healthy\"\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path, class_label):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if the image is grayscale\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append((img_array, class_label))\n",
    "    return image_data\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder, 0)  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder, 1)  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data), axis=0)\n",
    "np.random.shuffle(train_data)  # Shuffle the data\n",
    "x_train = np.array([data[0] for data in train_data])\n",
    "y_train = np.array([data[1] for data in train_data])\n",
    "\n",
    "# Create a simple CNN model\n",
    "model9 = keras.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Use softmax activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model9.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model9.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "model9.save(\"Citrus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image using the saved model\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    model = keras.models.load_model(\"Citrus\")\n",
    "    prediction = model.predict(img_array)\n",
    "    class_label = \"Citrus With Black Spot\" if prediction[0][0] < 0.5 else \"Healthy Citrus\"\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n",
      "Prediction: Healthy Citrus\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Citrus\\Citrus\\valid\\Citrus Black spot\\CitrusBlackSpot(2).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "Prediction: Citrus With Black Spot\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Citrus\\Citrus\\valid\\Citrus Healthy\\CitrusHealthy(3).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################Grape#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VAIBHAV\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 64s 383ms/step - loss: 0.5324 - accuracy: 0.7456\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 58s 361ms/step - loss: 0.2820 - accuracy: 0.9858\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 58s 359ms/step - loss: 0.2146 - accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 56s 350ms/step - loss: 0.1698 - accuracy: 0.9961\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 56s 350ms/step - loss: 0.1354 - accuracy: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Grape\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Grape\\assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths to the image folders\n",
    "class1_folder = r\"Grape\\Grape\\train\\Grape Black Measles\"\n",
    "class2_folder = r\"Grape\\Grape\\train\\Grape Healthy\"\n",
    "\n",
    "\n",
    "# Set the desired dimensions for the input images\n",
    "input_width, input_height = 224, 224\n",
    "\n",
    "# Load and preprocess the images from the folders\n",
    "def load_images_from_folder(folder_path, class_label):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if the image is grayscale\n",
    "        img = img.resize((input_width, input_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "        image_data.append((img_array, class_label))\n",
    "    return image_data\n",
    "\n",
    "# Load images from class1 folder\n",
    "class1_data = load_images_from_folder(class1_folder, 0)  # Assign class label 0 to class1\n",
    "\n",
    "# Load images from class2 folder\n",
    "class2_data = load_images_from_folder(class2_folder, 1)  # Assign class label 1 to class2\n",
    "\n",
    "# Combine the data and labels for training\n",
    "train_data = np.concatenate((class1_data, class2_data), axis=0)\n",
    "np.random.shuffle(train_data)  # Shuffle the data\n",
    "x_train = np.array([data[0] for data in train_data])\n",
    "y_train = np.array([data[1] for data in train_data])\n",
    "\n",
    "# Create a simple CNN model\n",
    "model10 = keras.Sequential([\n",
    "    layers.Conv2D(14, (3, 3), activation='relu', input_shape=(input_width, input_height, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(10, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Use softmax activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model10.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model10.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "model10.save(\"Grape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a new image\n",
    "def predict_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((input_width, input_height))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values between 0 and 1\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch\n",
    "    prediction = model10.predict(img_array)\n",
    "    class_label = \"Grape With Black Measles\" if prediction[0][0] < 0.5 else \"Healthy Grape\"\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n",
      "Prediction: Grape With Black Measles\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Grape\\Grape\\valid\\Grape Black Measles\\GrapeBlackMeasles(1).JPG\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prediction: Grape With Black Measles\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to a new image for prediction\n",
    "new_image_path = r\"Grape\\Grape\\valid\\Grape Healthy\\GrapeHealthy(12).jpg\"\n",
    "prediction = predict_image(new_image_path)\n",
    "print(\"Prediction:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
